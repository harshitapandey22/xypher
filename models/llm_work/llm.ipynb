{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0658b76-6304-4c95-8ab3-0ac8838c4b28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import langchain\n",
    "from openai import OpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from datetime import datetime\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29e36346-e8de-43c0-93c9-8e71d1200002",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "  base_url=\"https://openrouter.ai/api/v1\",\n",
    "  api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a5c8775-844b-4116-b41b-f8f0bc5e8c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bette\\AppData\\Local\\Temp\\ipykernel_21656\\173932313.py:1: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding_model = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
      "C:\\Users\\bette\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "C:\\Users\\bette\\AppData\\Local\\Temp\\ipykernel_21656\\173932313.py:3: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  db = Chroma(\n"
     ]
    }
   ],
   "source": [
    "embedding_model = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "db = Chroma(\n",
    "    collection_name=\"remember_collection\",\n",
    "    embedding_function=embedding_model,\n",
    "    persist_directory=\"./chroma_store\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "407c6f50-b6bf-494f-a709-f11d32b152a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_text(query, user):\n",
    "    db.add_texts(\n",
    "        texts = [query],\n",
    "        metadatas=[{\"author\": user,\"timestamp\": datetime.utcnow().isoformat()}]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c63220e6-8399-42fd-a4be-2342fa6d7aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_all_from(user):\n",
    "    results = db.get(where={\"author\": user})\n",
    "    for items in results:\n",
    "        combined = list(zip(results['documents'],results['metadatas']))\n",
    "    sorted_by_time = sorted(combined, key=lambda x: x[1][\"timestamp\"], reverse=True)\n",
    "    return sorted_by_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c03b6fd-d1bb-4f56-ac5e-7490a45ae8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_last_three(user):\n",
    "    messages = []\n",
    "    sorted_by_time = return_all_from(user)\n",
    "    if sorted_by_time is None:\n",
    "        return \"None\"\n",
    "        \n",
    "    flag = 0\n",
    "    for text, meta in sorted_by_time:\n",
    "        messages.append(text)\n",
    "        if flag == 2:\n",
    "            break\n",
    "        flag += 1\n",
    "    return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f2b53a86-a90b-4813-b499-3837c8b70999",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_template = f\"\"\"\n",
    "You are a financial advisor. You are only allowed to provide financial advice and nothing else, except when the user asks about their previous messages or conversation history.\n",
    "\n",
    "Always think step-by-step internally, but never show your reasoning unless asked. Only show the final answer.\n",
    "\n",
    "You are a helpful, knowledgeable financial advisor who speaks in the first person.\n",
    "\n",
    "Your task is to answer the user's current question clearly, intelligently, and with enough detail to be genuinely helpful. Provide focused and practical financial advice that directly relates to the question. You may include brief examples or context if it helps the user understand.\n",
    "\n",
    "Your response should be clear, natural, and typically within 5 to 7 sentences, but it's okay to be a little longer if necessary to fully answer the question.\n",
    "\n",
    "If the user's question is **not related to financial topics**, politely say:\n",
    "\"I'm here to help with financial questions. Feel free to ask me anything related to finance!\"\n",
    "\n",
    "However, if the user is asking about their previous messages, conversation history, or system-level interactions, you may assist them in retrieving or summarizing their recent messages, even if it's not strictly financial.\n",
    "\n",
    "You may be given:\n",
    "\n",
    "1. **Recent User Messages (last 3):**  \n",
    "Use these **only if** the current question references them directly — for example, if the user is continuing a thought, asking a follow-up, or referring back to something just said.  \n",
    "Recent messages:\n",
    "{{last_user_messages}}\n",
    "\n",
    "If the current question does **not** reference the recent messages, **ignore them** completely in your response.\n",
    "\n",
    "Focus only on the user's current question:\n",
    "“{{text}}”\n",
    "\n",
    "Begin your answer after this line. Respond naturally and clearly, using \"I\" if referring to yourself.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0869512c-ed55-45b4-8b56-f4f629501b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_answer(query, user):\n",
    "    current_question = query\n",
    "    user = user\n",
    "    add_text(current_question,user)\n",
    "        \n",
    "    prompt_template = ChatPromptTemplate.from_messages(\n",
    "        [(\"system\", system_template), (\"user\", \"{text}\")]\n",
    "    )\n",
    "    final_prompt = prompt_template.format_messages(\n",
    "        last_user_messages=return_last_three(user),\n",
    "        text=current_question\n",
    "    )\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "    model=\"deepseek/deepseek-chat-v3-0324:free\",\n",
    "    messages=[{\"role\": \"user\", \"content\": str(final_prompt)}],\n",
    "    temperature = 0.9\n",
    "    )\n",
    "\n",
    "    if response and hasattr(response, 'choices') and len(response.choices) > 0:\n",
    "        print(response.choices[0].message.content)\n",
    "    else:\n",
    "        print(\"Sorry, I couldn't generate a response at this time.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "63a5be53-c293-4c93-82eb-a21df2df6264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It looks like you're asking about your previous questions. Since my primary role is to provide financial advice, I don’t keep a detailed history of past queries unless they’re part of the current conversation. However, your recent messages include asking about my role as a financial advisor and requesting a summary of your previous question. If you’d like, I can help clarify anything specific from our recent discussion or answer new financial questions—just let me know!\n"
     ]
    }
   ],
   "source": [
    "return_answer(\"my previous querys\",\"arty@gmail\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
